{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e02094-1174-4c34-b4b7-3ff60af44a56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "import pandas as pd\n",
    "\n",
    "def batch_match_anonymized_to_identified(anonymized_df, identified_df, match_columns, threshold=60, \n",
    "                                         anonymized_file=None, anonymized_sheet=None):\n",
    "    \"\"\"\n",
    "    Perform batched matching of anonymized rows to identified rows for large datasets.\n",
    "    \n",
    "    :param anonymized_df: DataFrame with anonymized data.\n",
    "    :param identified_df: DataFrame with identified data, including source metadata.\n",
    "    :param match_columns: List of columns to use for matching.\n",
    "    :param threshold: Minimum matching score to consider a match valid.\n",
    "    :param anonymized_file: The file name of the anonymized data.\n",
    "    :param anonymized_sheet: The sheet name of the anonymized data.\n",
    "    :return: DataFrame with matched results and metadata for tracking.\n",
    "    \"\"\"\n",
    "    anonymized_df = anonymized_df.copy()\n",
    "    identified_df = identified_df.copy()\n",
    "    \n",
    "    # Create concatenated strings for matching\n",
    "    anonymized_df['match_key'] = anonymized_df[match_columns].fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
    "    identified_df['match_key'] = identified_df[match_columns].fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
    "    \n",
    "    # Create dictionary for faster lookups\n",
    "    identified_keys = identified_df['match_key'].to_list()\n",
    "    identified_lookup = {key: idx for idx, key in enumerate(identified_keys)}\n",
    "    \n",
    "    # Initialize results\n",
    "    matches = []\n",
    "    for index, row in anonymized_df.iterrows():\n",
    "        key = row['match_key']\n",
    "        best_match = process.extractOne(key, identified_keys, scorer=fuzz.token_set_ratio)\n",
    "        \n",
    "        if best_match and best_match[1] >= threshold:\n",
    "            matched_idx = identified_lookup[best_match[0]]\n",
    "            matched_row = identified_df.iloc[matched_idx]\n",
    "            matches.append({\n",
    "                'Anonymized_Index': index,\n",
    "                'Anonymized_Key': key,\n",
    "                'Matched_Key': best_match[0],\n",
    "                'Match_Score': best_match[1],\n",
    "                'Matched_Row_Index_Excel': matched_row['Original_Row_Index'],  # Use the stored original row index\n",
    "                'Matched_Row_Details': matched_row.to_dict(),\n",
    "                'Anonymized_File_Name': anonymized_file,\n",
    "                'Anonymized_Sheet_Name': anonymized_sheet,\n",
    "                'Matched_File_Name': matched_row['Source_File_Name'],\n",
    "                'Matched_Sheet_Name': matched_row['Source_Sheet_Name'],\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "# Load Excel files\n",
    "file_jan = \"11201查處名單.xlsx\"\n",
    "file_feb = \"11202查處名單.xlsx\"\n",
    "file_mar = \"11203查處名單.xlsx\"\n",
    "\n",
    "# Specify sheets for anonymized and identified data\n",
    "anonymized_sheets = {\"Jan\": \"表A名單1\", \"Feb\": \"表A名單1\", \"Mar\": \"表A名單1\"}\n",
    "identified_sheets = {\"Jan\": \"表A名單2\", \"Feb\": \"表A名單2\", \"Mar\": \"表A名單2\"}\n",
    "\n",
    "# Load identified data with source metadata and original row index\n",
    "identified_dfs = []\n",
    "for file_name, sheet_name in zip([file_jan, file_feb, file_mar], \n",
    "                                 [identified_sheets[\"Jan\"], identified_sheets[\"Feb\"], identified_sheets[\"Mar\"]]):\n",
    "    df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "    df['Source_File_Name'] = file_name\n",
    "    df['Source_Sheet_Name'] = sheet_name\n",
    "    df['Original_Row_Index'] = df.index + 2  # Add 2 to align with Excel row indexing (1-based, includes header)\n",
    "    identified_dfs.append(df)\n",
    "\n",
    "# Combine identified data\n",
    "combined_identified_data = pd.concat(identified_dfs, ignore_index=True)\n",
    "\n",
    "# Load anonymized data for January\n",
    "data_jan_anonymized = pd.read_excel(file_jan, sheet_name=anonymized_sheets[\"Jan\"])\n",
    "\n",
    "# Perform matching\n",
    "match_columns = ['地號', '廠址']\n",
    "results_jan = batch_match_anonymized_to_identified(\n",
    "    data_jan_anonymized,\n",
    "    combined_identified_data,\n",
    "    match_columns,\n",
    "    threshold=60,\n",
    "    anonymized_file=file_jan,\n",
    "    anonymized_sheet=anonymized_sheets[\"Jan\"]\n",
    ")\n",
    "\n",
    "# Display results in Jupyter Notebook\n",
    "results_jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff9100-9f9c-4d74-85e5-76ecd61b78ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
